import os
import pickle
import time
import logging
from typing import Any, Dict, List, Optional

import torch.distributed as dist
from hivemind import DHT, get_dht_time

from genrl.communication.communication import Communication
from genrl.serialization.game_tree import from_bytes, to_bytes

logger = logging.getLogger(__name__)

class HivemindRendezvouz:
    _STORE = None
    _IS_MASTER = False
    _IS_LAMBDA = False
    _initial_peers: List[str] = [
        # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å —Å—é–¥–∞ –¥–µ—Ñ–æ–ª—Ç–Ω—ã—Ö –±—É—Å—Ç—Ä—ç–ø –ø–∏—Ä–æ–≤, –µ—Å–ª–∏ —Ö–æ—á–µ—à—å
        # "/ip4/38.101.215.15/tcp/30011/p2p/QmQ2gEXoPJg6iMBSUFWGzAabS2VhnzuS782Y637hGjfsRJ",
        # "/ip4/38.101.215.15/tcp/30012/p2p/QmWhiaLrx3HRZfgXc2i7KW5nMUNK7P9tRc71yFJdGEZKkC",
        # "/ip4/38.101.215.15/tcp/30013/p2p/QmQa1SCfYTxx7RvU7qJJRo79Zm1RAwPpkeLueDVJuBBmFp"
    ]

    @classmethod
    def init(cls, is_master: bool = False):
        cls._IS_MASTER = is_master
        cls._IS_LAMBDA = os.environ.get("LAMBDA", False)
        logger.info(f"?? HivemindRendezvouz.init: is_master={is_master}, is_lambda={cls._IS_LAMBDA}")
        if cls._STORE is None and cls._IS_LAMBDA:
            world_size = int(os.environ.get("HIVEMIND_WORLD_SIZE", 1))
            logger.info(f"?? Initializing TCPStore with world_size={world_size}")
            cls._STORE = dist.TCPStore(
                host_name=os.environ["MASTER_ADDR"],
                port=int(os.environ["MASTER_PORT"]),
                is_master=is_master,
                world_size=world_size,
                wait_for_workers=True,
            )

    @classmethod
    def is_bootstrap(cls) -> bool:
        return cls._IS_MASTER

    @classmethod
    def set_initial_peers(cls, initial_peers: List[str]):
        logger.info(f"?? Setting initial peers: {initial_peers}")
        if cls._STORE is None and cls._IS_LAMBDA:
            cls.init()
        if cls._IS_LAMBDA and cls._STORE is not None:
            cls._STORE.set("initial_peers", pickle.dumps(initial_peers))
            logger.info("? Initial peers stored in TCPStore")

    @classmethod
    def get_initial_peers(cls) -> List[str]:
        logger.info("?? Getting initial peers...")
        
        # –ï—Å–ª–∏ —Ö–æ—á–µ—à—å –æ—Ç–∫–ª—é—á–∏—Ç—å lookup –∏–∑ —Ü–µ–ø–æ—á–∫–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞)
        if not getattr(cls, 'force_chain_lookup', True):
            logger.info("??  force_chain_lookup=False, returning empty initial peers list")
            return []

        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è "–º–µ—Ä—Ç–≤—ã—Ö" –ø–∏—Ä–æ–≤ –ø–æ IP 38.101.215.15
        dead_ip_prefix = "/ip4/38.101.215.15"
        logger.info(f"?? Filtering dead peers with prefix: {dead_ip_prefix}")

        # –ü–æ–ª—É—á–∞–µ–º –ø–∏—Ä–æ–≤ –∏–∑ store, –µ—Å–ª–∏ –≤ —Ä–µ–∂–∏–º–µ lambda, –∏–Ω–∞—á–µ –∏–∑ _initial_peers
        if cls._STORE is not None and cls._IS_LAMBDA:
            logger.info("?? Getting peers from TCPStore...")
            cls._STORE.wait(["initial_peers"])
            peer_bytes = cls._STORE.get("initial_peers")
            if peer_bytes is not None:
                peers = pickle.loads(peer_bytes)
                logger.info(f"?? Loaded {len(peers)} peers from store: {peers}")
            else:
                peers = []
                logger.warning("??  No peers found in TCPStore")
        else:
            peers = cls._initial_peers
            logger.info(f"?? Using default peers: {peers}")

        alive_peers = [p for p in peers if not p.startswith(dead_ip_prefix)]
        filtered_count = len(peers) - len(alive_peers)
        
        if filtered_count > 0:
            logger.info(f"?? Filtered out {filtered_count} dead peers")

        if alive_peers:
            logger.info(f"? Returning {len(alive_peers)} alive initial peers: {alive_peers}")
            return alive_peers
        else:
            logger.warning("??  No alive initial peers found, returning empty list")
            logger.info("?? System will rely on blockchain bootnodes for network discovery")
            return []

class HivemindBackend(Communication):
    def __init__(
        self,
        initial_peers: Optional[List[str]] = None,
        timeout: int = 600,
        disable_caching: bool = False,
        beam_size: int = 1000,
        **kwargs,
    ):
        logger.info("?? Initializing HivemindBackend-optimized-with-initial-peers...")
        logger.info(f"?? Constructor initial_peers parameter: {initial_peers}")
        
        self.world_size = int(os.environ.get("HIVEMIND_WORLD_SIZE", 1))
        self.timeout = timeout
        self.bootstrap = HivemindRendezvouz.is_bootstrap()
        self.beam_size = beam_size
        self.dht = None

        logger.info(f"?? Configuration: world_size={self.world_size}, timeout={timeout}, bootstrap={self.bootstrap}")

        if disable_caching:
            kwargs['cache_locally'] = False
            kwargs['cache_on_store'] = False
            logger.info("?? Caching disabled")

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ initial_peers –∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º –∫–æ–¥–µ
        if self.bootstrap:
            # Bootstrap –Ω–æ–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–µ initial_peers (–º–æ–≥—É—Ç –±—ã—Ç—å None/–ø—É—Å—Ç—ã–µ)
            logger.info("???  Starting as BOOTSTRAP node...")
            if initial_peers:
                logger.info(f"?? Bootstrap using provided initial_peers: {initial_peers}")
            else:
                logger.info("?? Bootstrap starting with no initial_peers (standalone)")
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –º–µ—Ä—Ç–≤—ã—Ö –ø–∏—Ä–æ–≤ –¥–ª—è bootstrap —Ç–æ–∂–µ
            if initial_peers:
                dead_ip_prefix = "/ip4/38.101.215.15"
                alive_peers = [p for p in initial_peers if not p.startswith(dead_ip_prefix)]
                filtered_count = len(initial_peers) - len(alive_peers)
                if filtered_count > 0:
                    logger.info(f"?? Bootstrap: Filtered out {filtered_count} dead peers")
                    initial_peers = alive_peers
        else:
            # Participant –Ω–æ–¥–∞: –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–µ –ø–∏—Ä—ã –ò–õ–ò –ø–æ–ª—É—á–∞–µ–º –∏–∑ HivemindRendezvouz
            logger.info("?? Starting as PARTICIPANT node...")
            logger.info(f"?? Constructor initial_peers: {initial_peers}")
            
            if initial_peers is None:
                logger.warning("??  initial_peers is None, will call get_initial_peers()")
                try:
                    initial_peers = HivemindRendezvouz.get_initial_peers()
                    logger.info(f"? Retrieved initial_peers from HivemindRendezvouz: {initial_peers}")
                except Exception as e:
                    logger.error(f"?? Error getting initial_peers from HivemindRendezvouz: {e}")
                    logger.info("?? Falling back to empty list - will rely on blockchain coordination")
                    initial_peers = []
            else:
                logger.info(f"?? Using provided initial_peers: {initial_peers}")
                # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –º–µ—Ä—Ç–≤—ã—Ö –ø–∏—Ä–æ–≤
                dead_ip_prefix = "/ip4/38.101.215.15"
                alive_peers = [p for p in initial_peers if not p.startswith(dead_ip_prefix)]
                filtered_count = len(initial_peers) - len(alive_peers)
                if filtered_count > 0:
                    logger.info(f"?? Participant: Filtered out {filtered_count} dead peers")
                    initial_peers = alive_peers

        logger.info(f"?? Final initial_peers for DHT: {initial_peers}")

        if self.bootstrap:
            # Bootstrap –Ω–æ–¥–∞ ‚Äî –∑–∞–ø—É—Å–∫–∞–µ—Ç DHT —Å –∑–∞–¥–∞–Ω–Ω—ã–º–∏ initial_peers (–º–æ–∂–Ω–æ –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫)
            logger.info("???  Creating Bootstrap DHT...")
            self.dht = DHT(
                start=True,
                host_maddrs=["/ip4/0.0.0.0/tcp/0", "/ip4/0.0.0.0/udp/0/quic"],
                initial_peers=initial_peers,
                **kwargs,
            )
            dht_maddrs = self.dht.get_visible_maddrs(latest=True)
            HivemindRendezvouz.set_initial_peers(dht_maddrs)
            logger.info(f"? Bootstrap DHT started successfully!")
            logger.info(f"?? Bootstrap node visible addresses: {dht_maddrs}")
        else:
            # –£—á–∞—Å—Ç–Ω–∏–∫ —Å–µ—Ç–∏ ‚Äî –ø–æ–¥–∫–ª—é—á–∞–µ—Ç—Å—è –∫ bootstrap –ø–∏—Ä–∞–º–∏
            logger.info("?? Creating Participant DHT...")
            
            if not initial_peers:
                logger.warning("??  Starting DHT with empty initial_peers!")
                logger.info("?? Will rely on blockchain coordinator for network discovery")
                logger.info("?? This is NORMAL - system will connect to main network via blockchain bootnodes")
            
            self.dht = DHT(
                start=True,
                host_maddrs=["/ip4/0.0.0.0/tcp/0", "/ip4/0.0.0.0/udp/0/quic"],
                initial_peers=initial_peers,
                **kwargs,
            )
            logger.info(f"? Participant DHT started successfully!")
            logger.info(f"?? Connected with initial peers: {initial_peers}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ DHT —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω
        if self.dht is None:
            logger.error("? DHT initialization failed!")
            raise RuntimeError("DHT initialization failed")
        
        # –ü–æ–ª—É—á–∞–µ–º –∏ –ª–æ–≥–∏—Ä—É–µ–º peer ID
        self.peer_id = str(self.dht.peer_id)
        logger.info(f"?? Generated Peer ID: {self.peer_id}")
        
        # –ü–æ–ª—É—á–∞–µ–º –≤–∏–¥–∏–º—ã–µ –∞–¥—Ä–µ—Å–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–µ—Ç–µ–≤–æ–π —Å–≤—è–∑–Ω–æ—Å—Ç–∏
        try:
            visible_maddrs = self.dht.get_visible_maddrs(latest=True)
            logger.info(f"?? DHT visible addresses: {visible_maddrs}")
            
            if visible_maddrs:
                logger.info("? DHT is accessible from the network!")
            else:
                logger.warning("??  DHT has no visible addresses - possible network issues")
                
        except Exception as e:
            logger.error(f"? Error getting visible addresses: {e}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –¥—Ä—É–≥–∏–º –ø–∏—Ä–∞–º
        try:
            # –ü–æ–ø—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –±–ª–∏–∂–∞–π—à–∏—Ö –ø–∏—Ä–∞—Ö
            logger.info("?? Checking network connectivity...")
            
            # –î–∞–µ–º –≤—Ä–µ–º—è DHT –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è —Å–µ—Ç–∏
            time.sleep(2)
            
            # –ü—Ä–æ–≤–µ—Ä–∏–º, –µ—Å—Ç—å –ª–∏ —É –Ω–∞—Å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –¥—Ä—É–≥–∏–º –ø–∏—Ä–∞–º
            # –≠—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —É –Ω–∞—Å –µ—Å—Ç—å –¥—Ä—É–≥–∏–µ –ø–∏—Ä—ã –≤ —Å–µ—Ç–∏
            routing_table_size = len(self.dht.get_visible_maddrs(latest=True))
            logger.info(f"?? DHT routing table size: {routing_table_size}")
            
            if routing_table_size > 0:
                logger.info("? DHT has network connections - connected to swarm!")
            else:
                logger.info("??  DHT starting in isolated mode - will connect via blockchain coordination")
                
        except Exception as e:
            logger.warning(f"??  Could not check network connectivity: {e}")

        logger.info("?? HivemindBackend initialization complete!")
        logger.info("?? Next steps: SwarmCoordinator will get bootnodes from blockchain and register this peer")

        self.step_ = 0

    def all_gather_object(self, obj: Any) -> Dict[str | int, Any]:
        assert self.dht is not None, "DHT must be initialized before calling all_gather_object"
        
        start_time = time.monotonic()
        key = str(self.step_)
        logger.info(f"üîÑ all_gather_object START: step={self.step_}, world_size={self.world_size}")

        try:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–∏–¥–∏–º—ã—Ö –∞–¥—Ä–µ—Å–æ–≤
            maddrs_start = time.monotonic()
            visible_maddrs = self.dht.get_visible_maddrs(latest=True)
            maddrs_time = time.monotonic() - maddrs_start
            logger.info(f"üì° get_visible_maddrs: {len(visible_maddrs)} addresses in {maddrs_time:.2f}s")
            logger.info(f"üìç Visible addresses: {visible_maddrs}")

            # –°–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ–±—ä–µ–∫—Ç–∞
            serialize_start = time.monotonic()
            obj_bytes = to_bytes(obj)
            serialize_time = time.monotonic() - serialize_start
            logger.info(f"üì¶ Serialization took {serialize_time:.2f}s")

            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ DHT
            store_start = time.monotonic()
            self.dht.store(
                key,
                subkey=str(self.dht.peer_id),
                value=obj_bytes,
                expiration_time=get_dht_time() + self.timeout,
                beam_size=self.beam_size,
            )
            store_time = time.monotonic() - store_start
            logger.info(f"üíæ DHT store took {store_time:.2f}s")

            # –û–∂–∏–¥–∞–Ω–∏–µ –ø–µ—Ä–µ–¥ —Å–±–æ—Ä–æ–º
            logger.info("‚è±Ô∏è  Waiting 1s before gathering...")
            time.sleep(1)

            # –°–±–æ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            gather_start = time.monotonic()
            t_ = time.monotonic()
            iteration = 0

            while True:
                iteration += 1
                iter_start = time.monotonic()

                output_, _ = self.dht.get(key, beam_size=self.beam_size, latest=True)
                current_size = len(output_)

                iter_time = time.monotonic() - iter_start
                elapsed = time.monotonic() - t_

                logger.info(f"üîç Iteration {iteration}: got {current_size}/{self.world_size} responses in {iter_time:.2f}s (total: {elapsed:.1f}s)")

                if current_size >= self.world_size:
                    logger.info(f"‚úÖ Got all {self.world_size} responses!")
                    break
                else:
                    if elapsed > self.timeout:
                        logger.error(f"‚è∞ TIMEOUT after {elapsed:.1f}s! Got only {current_size}/{self.world_size}")
                        raise RuntimeError(
                            f"Failed to obtain {self.world_size} values for {key} within timeout."
                        )

                    # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 10 —Å–µ–∫—É–Ω–¥
                    if iteration % 10 == 0:
                        logger.warning(f"‚ö†Ô∏è  Still waiting: {current_size}/{self.world_size} after {elapsed:.1f}s")

            gather_time = time.monotonic() - gather_start
            logger.info(f"üìä Gathering took {gather_time:.2f}s in {iteration} iterations")

            self.step_ += 1

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            process_start = time.monotonic()
            tmp = sorted(
                [(key, from_bytes(value.value)) for key, value in output_.items()],
                key=lambda x: x[0],
            )
            process_time = time.monotonic() - process_start
            logger.info(f"‚öôÔ∏è  Processing results took {process_time:.2f}s")

            total_time = time.monotonic() - start_time
            logger.info(f"‚úÖ all_gather_object SUCCESS: total {total_time:.2f}s")

            return {key: value for key, value in tmp}

        except (BlockingIOError, EOFError) as e:
            total_time = time.monotonic() - start_time
            logger.error(f"‚ùå all_gather_object FAILED after {total_time:.2f}s: {e}")
            logger.info("üîÑ Falling back to local object only")
            if self.dht is not None:
                peer_id = str(self.dht.peer_id)
            else:
                peer_id = "unknown"
            return {peer_id: obj}

    def get_id(self):
        return str(self.dht.peer_id)
